
               ETAPA 1

Pentru oricare din tipul de fisiere log se va converti la un fisier log standrad
    - tipuri de fisiere
     *apache
     *nginx
     *syslog
     *custume
     *JSON 
     *stack trage

     Fisierul standard va avea urmatoarea structura:
            {
    "timestamp": datetime sau None,
    "level": "DEBUG" / "INFO" / "WARN" / "ERROR" / "FATAL" / None,
    "message": "textul mesajului",
    "ip": "x.x.x.x" sau None,
    "method": "GET" / "POST" / etc. sau None,
    "path": "/index" / "/login" / etc. sau None,
    "status": int sau None,          # cod HTTP (200, 404, 500)
    "user_agent": "Mozilla/5.0" sau None,
    "process": "sshd" / "kernel" / None,
    "source": "apache" / "nginx" / "syslog" / "json" / "custom"
}

1.Apche are campurile :
     timestamp

         ip

        method

         path

        status

2.nginx
      sunt doua tipuri: de acces 
                  192.168.0.10 - - [21/Nov/2025:10:20:45 +0200] "GET /index.html HTTP/1.1" 200 512
                             este identic cu apache, dar in detector.py apache ruleaza primul si e ok
                       de error     2024/10/10 14:33:12 [error] 1234#0: *25 open() "/var/www/html/file.html" failed (2: No such file or directory)

 3.SYSLOG CLASIC (RFC 3164):
    MMM DD HH:MM:SS HOST PROC[PID]: MESSAGE          
               timestamp
               process
               message
              source="syslog"

              din massage putem sa exetragem si ip


4.JSON   // aici fisierele log depind de tipul de fisier, noi il vom lua pe col mai coomplex
       
5.Custom    // nu are un tip standard
     
     2025-11-26 12:30:00 ERROR worker-1[123] 192.168.1.10 user login failed at /login


        timestamp,
        level,
        message,
        ip
        path
       process
        "source": "custom"


              ETAPA 2


    Se va cititi fiecare linie din fisierul dat, se va pune intr un dictionar separat, dictionarle ese vor pune intr o lista          
          programul loader.py  : citeste linnie cu linie din fisierul log si o transpune in dictionarul standard, apor o pune intr o lista de dictionare

                  INPUT : un fisier de tip log 
                  OUTPUT :   [
  {
    "timestamp": datetime(...),
    "level": "INFO",
    "message": "GET /index.html",
    "ip": "192.168.1.10",
    "source": "apache"
  },
  {
    "timestamp": datetime(...),
    "level": "ERROR",
    "message": "Failed DB connection",
    "ip": "10.0.0.5",
    "source": "apache"
  },
  ...
]
           MOD DE LUCRU

           functia load_logs(file_path):

                      1. creezi o listă goală: entries = []

                       2. deschizi fișierul

                       3. pentru fiecare linie:
        
                        4. la final returnezi lista entries


           In folderul grouping se vor forma dictionare in functie de fieare elemnt din dictionarul standard, cu ajutorul listei de dictionare


MENIURILE ESTENTIALE

      Filtrare:
  --errors
  --filter TEXT
  --after data

Statistici:
  --stats
   Analiză Log-uri - apache.log
═══════════════════════════════════════════════
Total linii procesate: 300
Perioadă: 2025-01-14 02:20 - 2025-01-15 22:33

Distribuție pe niveluri:
  INFO   : 148 (49.3%)
  WARN   : 82 (27.3%)
  ERROR  : 58 (19.3%)
  FATAL  : 12 (4.0%)

Distribuție pe coduri HTTP:
  200    : 174
  404    : 41
  500    : 32
  302    : 23
  alte   : 30

Metode HTTP:
  GET    : 242
  POST   : 38
  PUT    : 14
  DELETE : 6

Top 5 IP-uri:
  192.168.0.17   : 28 requests
  192.168.0.22   : 25
  10.0.0.8       : 18
  203.0.113.5    : 16
  172.16.0.2     : 15
═══════════════════════════════════════════════

IP Analysis:
  --top_ips N
  --suspicious

Temporal:
  --group_by hour
  --spikes

Rapoarte:
  --report html --output FILE
  --report txt --output FILE

Dashboard:
  --watch FILE
  --alerts

           
 AI prediction

 --ai          