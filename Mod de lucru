
               ETAPA 1

Pentru oricare din tipul de fisiere log se va converti la un fisier log standrad
    - tipuri de fisiere
     *apache
     *nginx
     *syslog
     *custume
     *JSON 
     *stack trage

     Fisierul standard va avea urmatoarea structura:
            {
    "timestamp": datetime sau None,
    "level": "DEBUG" / "INFO" / "WARN" / "ERROR" / "FATAL" / None,
    "message": "textul mesajului",
    "ip": "x.x.x.x" sau None,
    "method": "GET" / "POST" / etc. sau None,
    "path": "/index" / "/login" / etc. sau None,
    "status": int sau None,          # cod HTTP (200, 404, 500)
    "user_agent": "Mozilla/5.0" sau None,
    "process": "sshd" / "kernel" / None,
    "source": "apache" / "nginx" / "syslog" / "json" / "custom"
}

1.Apche are campurile :
     timestamp

         ip

        method

         path

        status

2.nginx
      sunt doua tipuri: de acces 
                  192.168.0.10 - - [21/Nov/2025:10:20:45 +0200] "GET /index.html HTTP/1.1" 200 512
                             este identic cu apache, dar in detector.py apache ruleaza primul si e ok
                       de error     2024/10/10 14:33:12 [error] 1234#0: *25 open() "/var/www/html/file.html" failed (2: No such file or directory)

 3.SYSLOG CLASIC (RFC 3164):
    MMM DD HH:MM:SS HOST PROC[PID]: MESSAGE          
               timestamp
               process
               message
              source="syslog"

              din massage putem sa exetragem si ip


4.JSON   // aici fisierele log depind de tipul de fisier, noi il vom lua pe col mai coomplex
       
5.Custom    // nu are un tip standard
     
     2025-11-26 12:30:00 ERROR worker-1[123] 192.168.1.10 user login failed at /login


        timestamp,
        level,
        message,
        ip
        path
       process
        "source": "custom"


              ETAPA 2


    Se va cititi fiecare linie din fisierul dat, se va pune intr un dictionar separat, dictionarle ese vor pune intr o lista          
          programul loader.py  : citeste linnie cu linie din fisierul log si o transpune in dictionarul standard, apor o pune intr o lista de dictionare

                  INPUT : un fisier de tip log 
                  OUTPUT :   [
  {
    "timestamp": datetime(...),
    "level": "INFO",
    "message": "GET /index.html",
    "ip": "192.168.1.10",
    "source": "apache"
  },
  {
    "timestamp": datetime(...),
    "level": "ERROR",
    "message": "Failed DB connection",
    "ip": "10.0.0.5",
    "source": "apache"
  },
  ...
]
           MOD DE LUCRU

           functia load_logs(file_path):

                      1. creezi o listă goală: entries = []

                       2. deschizi fișierul

                       3. pentru fiecare linie:
        
                        4. la final returnezi lista entries


           In folderul grouping se vor forma dictionare in functie de fieare elemnt din dictionarul standard, cu ajutorul listei de dictionare


MENIURILE ESTENTIALE

      Filtrare:
  --errors
  --filter TEXT
  --after data
  --befor data
  --filter interval
  filter dupa text
Statistici:
  --stats
 Spike
  --skike_error
  --skike_abuse
   
IP Analysis:
  --top_ips N
  --suspicious

Temporal:
  --group_by hour
  --spikes

Rapoarte:
  --report html --output FILE
  --report txt --output FILE

Dashboard:
  --watch FILE
  --alerts

           
 AI prediction

 --ai          


 Meniul principal
            LOG ANALYZER — Meniu principal
1. Încărcare fișier log
2. Filtrare log-uri
3. Statistici generale
4. Top-uri (IP, erori, rute)
5. Detectare atacuri / IP-uri suspecte
6. Spike detection (creșteri bruște)
7. Generare rapoarte (HTML / TXT / JSON)
8. Monitorizare în timp real (--watch)
9. Setări
0. Ieșire
Alege opțiunea:



           RAPORT html -continut

              
Statistici generale
✔️ Distribuție pe timp
✔️ Top erori
✔️ Profilare IP
✔️ Top IP-uri suspecte
✔️ Spike-uri
✔️ Atacuri / pattern-uri suspecte
✔️ Recomandări finale